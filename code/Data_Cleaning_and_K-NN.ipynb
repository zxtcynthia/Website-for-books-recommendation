{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from re import sub\n",
    "from decimal import Decimal\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random select 50000 data from isbn.cvs\n",
    "# ind = np.random.choice(isbn_data.index, 50000, replace=False)\n",
    "# data = isbn_data.values[ind, :]\n",
    "# mydata = pd.DataFrame(data)\n",
    "# mydata.to_csv('sub_isbn.csv',cols=['ISBN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isbn_data = pd.read_csv('sub_isbn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r1 = open('result_full.json')\n",
    "d1 = json.load(r1)\n",
    "r2 = open('Output.json')\n",
    "d2 = json.load(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove(obj):\n",
    "    new_dict = dict()\n",
    "    for k,v in obj.items():\n",
    "        if v['rank'] is None:\n",
    "            continue\n",
    "        else:\n",
    "            new_dict[k]=v\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d_with_value = remove(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning and integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "list_keys = list()\n",
    "l = list(d_with_value.keys())\n",
    "for i in range(len(l)):\n",
    "    list_keys.append(l[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_knn = pd.DataFrame(np.zeros([17406, 11]))\n",
    "for i in range(17406):\n",
    "    data_knn.loc[i, 0] = list_keys[i]\n",
    "    data_knn.loc[i, 1] = int(('').join((d_with_value[list_keys[i]]['Cutomers Reviews'].split()[0]).split(',')))\n",
    "    data_knn.loc[i, 2] = d_with_value[list_keys[i]]['Ratings']['1']\n",
    "    data_knn.loc[i, 3] = d_with_value[list_keys[i]]['Ratings']['2']\n",
    "    data_knn.loc[i, 4] = d_with_value[list_keys[i]]['Ratings']['3']\n",
    "    data_knn.loc[i, 5] = d_with_value[list_keys[i]]['Ratings']['4']\n",
    "    data_knn.loc[i, 6] = d_with_value[list_keys[i]]['Ratings']['5']\n",
    "    data_knn.loc[i, 7] = d_with_value[list_keys[i]]['Ratings']['average score']\n",
    "    data_knn.loc[i, 8] = d_with_value[list_keys[i]]['category']\n",
    "    data_knn.loc[i, 9] = d_with_value[list_keys[i]]['rank']\n",
    "    data_knn.loc[i, 10] = d_with_value[list_keys[i]]['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_knn.columns = ['ISBN', 'Customer reviews', 'Ratings-1', 'Ratings-2',\n",
    "                    'Ratings-3', 'Ratings-4', 'Ratings-5', 'Average score', 'Category', 'Rank', 'Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_knn_clean = data_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_knn_clean\n",
    "data_knn_clean.to_csv('data_knn_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert rank to integer number and re-rank it as 1,2,3,...\n",
    "rank_list = list(data_knn['Rank'])\n",
    "rank_int = list()\n",
    "for i in range(17406):\n",
    "    split = rank_list[i].split(',')\n",
    "    rank_int.append(int(''.join(split)))\n",
    "array = np.array(rank_int)\n",
    "rank_new = array.argsort()+1\n",
    "data_knn_clean['Rank'] = rank_new\n",
    "# data_knn[data_knn['Rank']==34]\n",
    "\n",
    "# convert price to float with 2 or 1 decimal places\n",
    "price_list = list()\n",
    "for i in range(17406):\n",
    "    price_list.append(float(list(data_knn['Price'])[i]))\n",
    "data_knn_clean['Price'] = price_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert ratings to float number\n",
    "r_1 = list()\n",
    "r_2 = list()\n",
    "r_3 = list()\n",
    "r_4 = list()\n",
    "r_5 = list()\n",
    "for i in range(17406):\n",
    "    r_1.append(float(list(data_knn['Ratings-1'])[i].strip('%')))\n",
    "    r_2.append(float(list(data_knn['Ratings-2'])[i].strip('%')))\n",
    "    r_3.append(float(list(data_knn['Ratings-3'])[i].strip('%')))\n",
    "    r_4.append(float(list(data_knn['Ratings-4'])[i].strip('%')))\n",
    "    r_5.append(float(list(data_knn['Ratings-5'])[i].strip('%')))\n",
    "\n",
    "data_knn_clean['Ratings-1'] = r_1\n",
    "data_knn_clean['Ratings-2'] = r_2\n",
    "data_knn_clean['Ratings-3'] = r_3\n",
    "data_knn_clean['Ratings-4'] = r_4\n",
    "data_knn_clean['Ratings-5'] = r_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "knn_dummy = pd.get_dummies(data_knn_clean['Category'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = data_knn_clean\n",
    "df = df.drop('Category', 1)\n",
    "data_knn_final = pd.concat([df,knn_dummy],axis=1,join_axes=[df.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_knn_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe for K-NN calculation - data_knn_final saved as data_knn_final.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract all 17406 ISBN that has value\n",
    "# pd.DataFrame(list(data_knn_final['ISBN'])).to_csv('isbn_with_value.csv',cols=['ISBN'])\n",
    "# data_knn_final.to_csv('data_knn_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-NN model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user = pd.read_csv('user_knn.csv')\n",
    "user = user.drop('Book.Rating', 1)\n",
    "user_1 = data_knn_final[data_knn_final['ISBN'].isin(user['ISBN'])]\n",
    "data_knn = pd.merge(user, user_1, on='ISBN')\n",
    "# train and test set\n",
    "index = np.random.rand(len(data_knn)) < 0.80\n",
    "train_x = data_knn[index].iloc[:,]  # eliminate ISBN in calculation\n",
    "test_x = data_knn[~index].iloc[:,]\n",
    "scaled_train = pd.DataFrame(scale(train_x.iloc[:, 2:]), index=train_x.index, columns=train_x.columns[2:])\n",
    "scaled_test = pd.DataFrame(scale(test_x.iloc[:, 2:]), index=test_x.index, columns=test_x.columns[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaled_train = pd.DataFrame(scale(train_x.iloc[:, 2:]), index=train_x.index, columns=train_x.columns[2:])\n",
    "scaled_test = pd.DataFrame(scale(test_x.iloc[:, 2:]), index=test_x.index, columns=test_x.columns[2:])\n",
    "# scaled_train.columns\n",
    "weights = [0.008641099,0.00217803,0.00217803,0.00217803,0.00217803,0.00217803,0.008641099,0.008641099,0.008641099,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727,0.027272727]\n",
    "# assign weights to each columns\n",
    "scaled_test = scaled_test.multiply(weights)\n",
    "scaled_train = scaled_train.multiply(weights)\n",
    "train_x_scaled = pd.concat([scaled_train, train_x.iloc[:,11:]],axis=1,join_axes=[scaled_train.index])\n",
    "test_x_scaled = pd.concat([scaled_test, test_x.iloc[:,11:]],axis=1,join_axes=[scaled_test.index])\n",
    "# for each data point in test_x, compared with all datapoints in train_x\n",
    "d = np.zeros(shape=(len(train_x_scaled), len(test_x_scaled)))\n",
    "for i in range(len(test_x_scaled)):\n",
    "    for j in range(len(train_x_scaled)):\n",
    "        d[j, i] = np.sum(abs(test_x_scaled.values[i, ] - train_x_scaled.values[j, ]))\n",
    "distance_df = pd.DataFrame(d)\n",
    "# distance_df.shape # 2189 * 658"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try different k and compare accuracy\n",
    "def knn(k):\n",
    "\n",
    "    train_pool = list()\n",
    "    for t in range(0, len(test_x_scaled)):\n",
    "        dist_sort = distance_df.iloc[:, t].sort_values(ascending=True)\n",
    "        dist_sort_df = pd.DataFrame(dist_sort)\n",
    "        # index of nearest k neighbors\n",
    "        dist_index = dist_sort_df.iloc[0:k, 0].index.values\n",
    "        train_pool.append(sorted(dist_index))\n",
    "    \n",
    "    train_pool = np.asarray(train_pool)\n",
    "\n",
    "    pred_pool = list()\n",
    "    for i in range(len(test_x)):\n",
    "        user_id = train_x[train_x['ISBN'] == test_x['ISBN'].values[i]].values[:, 0]\n",
    "        all_user = list()\n",
    "        for j in range(len(user_id)):\n",
    "            all_isbn = train_x[train_x['User.ID'] == user_id[j]].index\n",
    "            all_user.extend(all_isbn)\n",
    "        pred_pool.append(sorted(all_user))\n",
    "\n",
    "    pred_pool = np.asarray(pred_pool)\n",
    "\n",
    "    count = 0\n",
    "    for item in range(len(pred_pool)):\n",
    "        if set(train_pool[item]) & set(pred_pool[item]):\n",
    "            count += 1\n",
    "    return count/len(pred_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# knn(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend by k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_nn(input_isbn):\n",
    "    user = pd.read_csv('all_user_match.csv').drop('Book.Rating', 1)  # 4475\n",
    "    data_knn_final = pd.read_csv('data_knn_final.csv')  # 17406\n",
    "    user_1 = data_knn_final[data_knn_final['ISBN'].isin(user['ISBN'])]\n",
    "    d = pd.merge(user, user_1, on='ISBN')\n",
    "    data_knn = d.drop(d.columns[2:6], axis=1)\n",
    "    data_knn_scaled = pd.DataFrame(scale(data_knn.iloc[:, 2:7]), index=data_knn.index, columns=data_knn.columns[2:7])\n",
    "    d_new = data_knn.drop(data_knn.columns[2:7],axis = 1)\n",
    "    data_knn_1 = pd.concat([data_knn_scaled,d_new],axis=1,join_axes=[data_knn_scaled.index])\n",
    "    \n",
    "    if input_isbn not in list(data_knn['ISBN']): # for the data we have user info, we return k-nn results\n",
    "        find_index = data_knn_final[data_knn_final['ISBN'] == input_isbn].index\n",
    "        row_select = pd.DataFrame(data_knn_final.iloc[find_index].iloc[0,10:]).T\n",
    "        category = row_select.columns[(row_select == 1).iloc[0]][0]\n",
    "        all_same_cat = data_knn_final[data_knn_final[category] == 1]\n",
    "        get_ave_score = all_same_cat.sort_values(by = 'Average score', ascending=False)\n",
    "        index_list = list(get_ave_score.index[0:5])\n",
    "        ISBN_list = list(get_ave_score.loc[index_list]['ISBN'])\n",
    "        if input_isbn in ISBN_list:\n",
    "            ISBN_list.remove(input_isbn)\n",
    "        else:\n",
    "            ISBN_list=ISBN_list[:4]\n",
    "    else:\n",
    "        test_x = (pd.DataFrame(data_knn_1[data_knn_1['ISBN'] == input_isbn].iloc[0,:]).T).drop(['User.ID','ISBN'],axis = 1)\n",
    "        train_x = (data_knn_1[data_knn_1['ISBN'] != input_isbn].iloc[:,:]).drop_duplicates('ISBN')\n",
    "        train_x_1 = train_x.drop(['User.ID','ISBN'],1)\n",
    "        d = np.zeros(shape=(len(train_x_1), 1))\n",
    "        for j in range(len(train_x_1)):\n",
    "             d[j] = np.sum(abs(test_x.values - train_x_1.values[j, ]))\n",
    "        distance_df = pd.DataFrame(d)\n",
    "        distance_df.columns = ['distance']\n",
    "        distance_sort = pd.DataFrame(distance_df.iloc[:, 0].sort_values(ascending=True))\n",
    "        index_list = distance_sort.index[0:5]\n",
    "        data_list = train_x_1.iloc[index_list]\n",
    "        index_list_1 = data_list.index.values.tolist()\n",
    "        ISBN_list = list(data_knn_1.iloc[index_list_1]['ISBN'])\n",
    "        if input_isbn in ISBN_list:\n",
    "            ISBN_list.remove(input_isbn)\n",
    "        else:\n",
    "            ISBN_list=ISBN_list[:4]\n",
    "        \n",
    "    return ISBN_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1566192943', '1862911827', '1402201400', '157120153X']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_isbn = '1572702516'\n",
    "find_nn(input_isbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_knn[data_knn['ISBN'] == '0743437772']\n",
    "user = pd.read_csv('all_user_match.csv').drop('Book.Rating', 1)  # 4475\n",
    "data_knn_final = pd.read_csv('data_knn_final.csv')  # 17406\n",
    "user_1 = data_knn_final[data_knn_final['ISBN'].isin(user['ISBN'])]\n",
    "d = pd.merge(user, user_1, on='ISBN')\n",
    "data_knn = d.drop(d.columns[2:6], axis=1)\n",
    "data_knn_scaled = pd.DataFrame(scale(data_knn.iloc[:, 2:7]), index=data_knn.index, columns=data_knn.columns[2:7])\n",
    "d_new = data_knn.drop(data_knn.columns[2:7],axis = 1)\n",
    "data_knn_1 = pd.concat([data_knn_scaled,d_new],axis=1,join_axes=[data_knn_scaled.index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_x = (pd.DataFrame(data_knn_1[data_knn_1['ISBN'] == input_isbn].iloc[0,:]).T).drop(['User.ID','ISBN'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend by User ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_books(user_id):\n",
    "    from operator import itemgetter\n",
    "    user_match = pd.read_csv('all_user_match.csv')\n",
    "    user_match\n",
    "    all_isbn = list(user_match[user_match['User.ID'] == user_id]['ISBN'])\n",
    "    all_id = list()\n",
    "    for i in range(len(all_isbn)):\n",
    "        all_id.extend(list(user_match[user_match['ISBN'] == all_isbn[i]]['User.ID']))\n",
    "    all_isbn_1 = list()\n",
    "    for j in range(len(all_id)):\n",
    "        all_isbn_1.extend(list(user_match[user_match['User.ID'] == all_id[j]]['ISBN']))\n",
    "    unique_isbn = list(set(all_isbn_1))\n",
    "    if len(unique_isbn) <= 4:\n",
    "        return unique_isbn\n",
    "    else:\n",
    "        find_score = dict()\n",
    "        order_isbn = list()\n",
    "        for i in range(len(unique_isbn)):\n",
    "            find_score[unique_isbn[i]] = (np.sum(user_match[user_match['ISBN'] == unique_isbn[i]]['Book.Rating']))/len(user_match[user_match['ISBN'] == unique_isbn[i]]['Book.Rating'])\n",
    "        result = sorted(find_score.items(), key = itemgetter(1), reverse = True)\n",
    "        for item in range(4):\n",
    "            order_isbn.append(result[item][0])\n",
    "        return order_isbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['069811681X', '087842055X', '1557482357', '055321392X']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_books(3145)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# user_match = pd.read_csv('all_user_match.csv')\n",
    "# user_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe for wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_wordcloud = pd.DataFrame(np.zeros([17406, 13]))\n",
    "for i in range(17406):\n",
    "    data_wordcloud.loc[i, 0] = list_keys[i]\n",
    "    try:\n",
    "        data_wordcloud.loc[i, 1] = d_with_value[list_keys[i]]['Introduction']\n",
    "    except KeyError:\n",
    "        data_wordcloud.loc[i, 1] = 'NA'\n",
    "    try:\n",
    "        data_wordcloud.loc[i, 2] = d_with_value[list_keys[i]]['Stars']['0']\n",
    "    except:\n",
    "        data_wordcloud.loc[i, 2] = 'NA'\n",
    "    try:\n",
    "        data_wordcloud.loc[i, 3] = d_with_value[list_keys[i]]['Stars']['1']\n",
    "    except KeyError:\n",
    "        data_wordcloud.loc[i, 3] = 'NA'\n",
    "    try:\n",
    "        data_wordcloud.loc[i, 4] = d_with_value[list_keys[i]]['Stars']['2']\n",
    "    except KeyError:\n",
    "        data_wordcloud.loc[i, 4] = 'NA'\n",
    "    try:\n",
    "        data_wordcloud.loc[i, 5] = d_with_value[list_keys[i]]['Stars']['3']\n",
    "    except KeyError:\n",
    "        data_wordcloud.loc[i, 5] = 'NA'\n",
    "    try:\n",
    "        data_wordcloud.loc[i, 6] = d_with_value[list_keys[i]]['Stars']['4']\n",
    "    except KeyError:\n",
    "        data_wordcloud.loc[i, 6] = 'NA'\n",
    "    try:\n",
    "        data_wordcloud.loc[i, 7] = d_with_value[list_keys[i]]['Stars']['5']\n",
    "    except KeyError:\n",
    "        data_wordcloud.loc[i, 7] = 'NA'\n",
    "    try:\n",
    "        data_wordcloud.loc[i, 8] = d_with_value[list_keys[i]]['Stars']['6']\n",
    "    except KeyError:\n",
    "        data_wordcloud.loc[i, 8] = 'NA'\n",
    "    try:\n",
    "        data_wordcloud.loc[i, 9] = d_with_value[list_keys[i]]['Stars']['7']\n",
    "    except KeyError:\n",
    "        data_wordcloud.loc[i, 9] = 'NA'\n",
    "    try:\n",
    "        data_wordcloud.loc[i, 10] = d_with_value[list_keys[i]]['author']\n",
    "    except KeyError:\n",
    "        data_wordcloud.loc[i, 10] = 'NA'\n",
    "    try:\n",
    "        data_wordcloud.loc[i, 11] = d_with_value[list_keys[i]]['category']\n",
    "    except KeyError:\n",
    "        data_wordcloud.loc[i, 11] = 'NA'\n",
    "    try:\n",
    "        data_wordcloud.loc[i, 12] = d_with_value[list_keys[i]]['tags']\n",
    "    except KeyError:\n",
    "        data_wordcloud.loc[i, 12] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# data_wordcloud.columns = ['ISBN', 'Introduction', 'Star-0', 'Star-1', 'Star-2', 'Star-3',\n",
    "#                           'Star-4', 'Star-5', 'Star-6', 'Star-7', 'author', 'category', 'tags']\n",
    "# # data_wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
