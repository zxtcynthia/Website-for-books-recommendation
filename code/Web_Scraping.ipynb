{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('sub_isbn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/42.0.2311.90 Safari/537.36'}\n",
    "result={}\n",
    "for isbn in range(0,50000):\n",
    "    print(isbn)\n",
    "    ISBN=data.values[isbn][0].zfill(10)\n",
    "    amazon_url  = 'http://www.amazon.com/dp/'+ISBN \n",
    "    response = requests.get(amazon_url,headers = headers)\n",
    "    if response.status_code == 200: \n",
    "        page_response = BeautifulSoup(response.content,'lxml') \n",
    "        \n",
    "        try:\n",
    "            book_name = page_response.find('span', id = 'productTitle').get_text()\n",
    "            try:\n",
    "                author = page_response.find('div',id='byline').find('span',class_='author notFaded').find('a',{\"class\":'a-link-normal contributorNameID'}).get_text()\n",
    "            except:\n",
    "                try:\n",
    "                    author = page_response.find('div',id='byline').find('span',class_='author notFaded').find('a',{\"class\":'a-link-normal'}).get_text()\n",
    "                except:\n",
    "                    info={'Name':None,'author':None,'pages':None,'publisher':None,'language':None,'rank':None,'category':None,'tags':None} \n",
    "            details = page_response.find('table',id='productDetailsTable').find_all('li')\n",
    "            for row in details:\n",
    "                if 'page' in row.get_text().lower():\n",
    "                    pages=row.get_text().split(':')[1][1:]\n",
    "                if 'publisher:' in row.get_text().lower():\n",
    "                    publisher=row.get_text().split(':')[1][1:]\n",
    "                if 'language:' in row.get_text().lower():\n",
    "                    language=row.get_text().split(':')[1][1:]\n",
    "                if 'sellers rank:' in row.get_text().lower():\n",
    "                    rank=row.get_text()\n",
    "                    totalrank=rank[rank.index('#')+1:rank.index('(')-1].split(' ')[0]\n",
    "                    sr = row.find_all('li', class_='zg_hrsr_item')\n",
    "                    c=re.sub(\"[^a-zA-Z0-9&>,'-]\", ' ', sr[0].get_text())\n",
    "                    category=c.split('>')[1].strip()\n",
    "                    tag = []\n",
    "                    for i in range(len(sr)):\n",
    "                        sub = re.sub(\"[^a-zA-Z0-9&>,'-]\",\n",
    "                                     ' ', sr[i].get_text())\n",
    "                        sub = re.sub(' in ', '', sub)\n",
    "                        sub = re.sub('Books', '', sub)\n",
    "                        sub = sub.split('>')\n",
    "                        for j in range(len(sub)):\n",
    "                            sub[j] = sub[j].strip()\n",
    "                        tag.append(sub[-1])\n",
    "\n",
    "                \n",
    "            reviews_list_1 = []\n",
    "            reviews_list_2 = []\n",
    "            a = page_response.find(\n",
    "                'div', {'id': 'most-recent-reviews-content'})\n",
    "            b = a.find_all('div', {'data-hook': 'recent-review'})\n",
    "            for i in b:\n",
    "                c = i.find('span', {'class': 'a-icon-alt'}).get_text()\n",
    "                reviews_list_1.append(c)\n",
    "                x = list(range(len(reviews_list_1)))\n",
    "                y = dict(zip(x, reviews_list_1))\n",
    "            for i in b:\n",
    "                d = i.find(\n",
    "                    'span', {'data-hook': 'review-body-recent'}).get_text()\n",
    "                reviews_list_2.append(d)\n",
    "                w = list(range(len(reviews_list_2)))\n",
    "                z = dict(zip(w, reviews_list_2))\n",
    "                \n",
    "    \n",
    "            for t in page_response.find_all('span', {'class': 'a-size-medium a-color-price offer-price a-text-normal'}):\n",
    "                price_ = float(t.get_text()[1:])\n",
    "                \n",
    "            ########################### star distrution and average score               \n",
    "            ratings_dict = {}\n",
    "            for i in range (1,6):\n",
    "                rating_key=i\n",
    "                try:\n",
    "                    rating_value=page_response.find('a',class_=\"a-size-base a-link-normal \"+str(i)+\"star histogram-review-count\").get_text()\n",
    "                except AttributeError:\n",
    "                    rating_value='0%'\n",
    "                ratings_dict.update({rating_key: rating_value})\n",
    "            rating_key='average score'\n",
    "            average_score=0\n",
    "            for i in range(1,6):\n",
    "                if type(ratings_dict[i])!=int:\n",
    "                    a=round((i*float(ratings_dict[i].strip('%'))/100),2)\n",
    "                    average_score+=a\n",
    "            ratings_dict.update({rating_key: average_score})\n",
    "            ########################### customer reviews\n",
    "            try:\n",
    "                reviews_value=page_response.find('span',id=\"acrCustomerReviewText\").get_text()\n",
    "            except AttributeError:\n",
    "                reviews_value='0 reviews'\n",
    "            ###########################   introduction\n",
    "            try:\n",
    "                intro=str(page_response.find_all('noscript')[1])\n",
    "                intro=re.compile(r'<[^>]+>').sub('',intro)\n",
    "                intro = re.sub('[^a-zA-Z0-9-_*.,]', ' ', intro)\n",
    "            except AttributeError:\n",
    "                intro=None\n",
    "            info={'Name':book_name,'price': price_, 'author':author,'pages':pages,'publisher':publisher,'language':language,\n",
    "                  'rank':totalrank,'category':category,'tags':tag,'Reviews': y,'Stars': z,'Ratings':ratings_dict,'Cutomers Reviews':reviews_value,\n",
    "                  'Introduction':intro}                \n",
    "        except (AttributeError, ConnectionError, IndexError):\n",
    "            info={'Name':None,'price':None, 'author':None,'pages':None,'publisher':None,'language':None,\n",
    "                  'rank':None,'category':None,'tags':None,'Reviews': None,'Stars': None,'Ratings':None,'Cutomers Reviews':None,\n",
    "                  'Introduction':None} \n",
    "    result[ISBN]=info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('Output.json', 'w') as fp:\n",
    "    json.dump(result, fp)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
