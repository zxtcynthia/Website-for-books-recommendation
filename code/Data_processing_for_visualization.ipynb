{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Group: Synergy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is used for data processing for visualization parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Open the Json file\n",
    "testFile = open(\"result_full.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = json.load(testFile)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.transpose()\n",
    "\n",
    "# get rid of 'None'\n",
    "df = df[df.Name.notnull()]\n",
    "\n",
    "# edit column names\n",
    "df.columns = ['Reviews Count', 'Introduction', 'Name', 'Ratings', 'Stars', 'Reviews',\n",
    "              'Author', 'Category', 'Language', 'Pages', 'Price', 'Publisher', 'Rank', 'Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add ISBN list to the existing columns and change row index name\n",
    "df['ISBN'] = pd.Series(df.index.tolist(),index = df.index)\n",
    "df.index = range(17406)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#rearrange columns\n",
    "df1 = df[['ISBN','Name','Author','Language','Category','Tags','Pages','Price','Publisher','Rank','Introduction','Reviews Count','Ratings','Stars','Reviews']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1.loc[:,'Reviews Count'] = df1.loc[:,'Reviews Count'].apply(lambda x: str(x)[:-16].strip())\n",
    "df1.loc[:,'Pages'] = df1.loc[:,'Pages'].apply(lambda x: str(x)[:-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#language\n",
    "array = df1.Language.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(array)):\n",
    "    array[i] = array[i].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "array_flattened = [y for x in array for y in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "language_list = sorted(set(array_flattened))\n",
    "language_list.remove('English,')\n",
    "language_list.remove('French,')\n",
    "language_list.remove('German,')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dummy variables for languages:\n",
    "for language in language_list:\n",
    "    list1 = df1.Language.tolist()\n",
    "    for i in range(len(list1)):\n",
    "        if language in list1[i]:\n",
    "            list1[i] = 1\n",
    "        else:\n",
    "            list1[i] = 0\n",
    "    df1[language] = pd.Series(list1, index=df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      1\tBrazilian \n",
      "      1\tCatalan   \n",
      "      4\tChinese   \n",
      "      2\tDutch     \n",
      "  16978\tEnglish   \n",
      "    104\tFrench    \n",
      "     86\tGerman    \n",
      "      1\tGreek     \n",
      "     13\tItalian   \n",
      "      2\tJapanese  \n",
      "      1\tLatin     \n",
      "      1\tMultilingual\n",
      "      1\tOld       \n",
      "      4\tPortuguese\n",
      "      1\tSerbian   \n",
      "    251\tSpanish   \n",
      "      3\tTaiwanese \n"
     ]
    }
   ],
   "source": [
    "#language distribution:\n",
    "for language in language_list:\n",
    "    print(\"%7d\\t%-10s\"%(df1[language].sum(), language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dummy variables for categories\n",
    "category_array = df1.Category.unique()\n",
    "for category in category_array:\n",
    "    list1 = df1.Category.tolist()\n",
    "    for i in range(len(list1)):\n",
    "        if category in list1[i]:\n",
    "            list1[i] = 1\n",
    "        else:\n",
    "            list1[i] = 0\n",
    "    df1[category] = pd.Series(list1, index=df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     67\tEngineering & Transportation\n",
      "   4894\tLiterature & Fiction\n",
      "   1799\tChildren's\n",
      "    412\tHistory   \n",
      "    278\tScience & Math\n",
      "   1203\tMystery, Thriller & Suspense\n",
      "    180\tCookbooks, Food & Wine\n",
      "    577\tReligion & Spirituality\n",
      "     94\tMedical   \n",
      "    621\tPolitics & Social Sciences\n",
      "    234\tBusiness & Money\n",
      "    822\tScience Fiction & Fantasy\n",
      "    332\tReference \n",
      "    561\tBiographies & Memoirs\n",
      "    220\tSelf-Help \n",
      "    133\tSports & Outdoors\n",
      "    525\tTeens     \n",
      "    118\tParenting & Relationships\n",
      "    598\tTextbooks \n",
      "   1573\tRomance   \n",
      "    188\tTravel    \n",
      "    350\tHumor & Entertainment\n",
      "    342\tHealth, Fitness & Dieting\n",
      "    206\tCrafts, Hobbies & Home\n",
      "     33\tLaw       \n",
      "    220\tChristian  & Bibles\n",
      "     99\tComics & Graphic Novels\n",
      "    134\tLibros en espa ol\n",
      "    293\tArts & Photography\n",
      "    153\tComputers & Technology\n",
      "     17\tGay & Lesbian\n",
      "     84\tEducation & Teaching\n",
      "     16\ton CD     \n",
      "      1\tOutdoor D cor\n",
      "     28\tDeals     \n",
      "      1\tNovelty & More\n"
     ]
    }
   ],
   "source": [
    "#category distribution:\n",
    "for category in category_array:\n",
    "    print(\"%7d\\t%-10s\"%(df1[category].sum(),category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract publisher info from the 'Publisher' column\n",
    "df1['Publisher_only'] = df1['Publisher']\n",
    "df1.loc[:, 'Publisher_only'] = df1.loc[:, 'Publisher_only'].apply(\n",
    "    lambda x: re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", x))\n",
    "df1.loc[:, 'Publisher_only'] = df1.loc[\n",
    "    :, 'Publisher_only'].apply(lambda x: x.split(\";\", 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4417"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_array = df1.Publisher_only.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'September 3, 1979'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract publish time info from the 'Publisher' column\n",
    "regex = re.compile(\".*?\\((.*?)\\)\")\n",
    "re.findall(regex, df1.Publisher[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "time_list = list()\n",
    "for i in range(len(df1.Publisher)):\n",
    "    result = re.findall(regex, df1.Publisher[i])\n",
    "    time_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-723c3f4f0f3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdateutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdateparser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mformatted_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mformatted_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdateparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%m/%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time_list' is not defined"
     ]
    }
   ],
   "source": [
    "from dateutil import parser as dateparser\n",
    "formatted_time = list()\n",
    "for i in range(len(time_list)):\n",
    "    try:\n",
    "        formatted_time.append(dateparser.parse(\n",
    "            ''.join(time_list[i])).strftime('%m/%Y'))\n",
    "    except:\n",
    "        formatted_time.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['Publish_time'] = pd.Series(formatted_time,index = df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ratings_dicts = df1.Ratings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "average_score = list()\n",
    "for i in ratings_dicts:\n",
    "    average_score.append(i.get('average score'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['Average_Rating'] = pd.Series(average_score,index = df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_star_percent = list()\n",
    "for i in ratings_dicts:\n",
    "    one_star_percent.append(i.get('1'))\n",
    "#one_star_percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "one_star_percent = [int(re.sub(\"%\",\"\",i)) for i in one_star_percent]\n",
    "one_star_percent = [i/100 for i in one_star_percent]\n",
    "#one_star_percent\n",
    "df1['One_star'] = pd.Series(one_star_percent,index = df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two_star_percent = list()\n",
    "for i in ratings_dicts:\n",
    "    two_star_percent.append(i.get('2'))\n",
    "two_star_percent = [int(re.sub(\"%\",\"\",i)) for i in two_star_percent]\n",
    "two_star_percent = [i/100 for i in two_star_percent]\n",
    "df1['Two_star'] = pd.Series(two_star_percent,index = df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "three_star_percent = list()\n",
    "for i in ratings_dicts:\n",
    "    three_star_percent.append(i.get('3'))\n",
    "three_star_percent = [int(re.sub(\"%\",\"\",i)) for i in three_star_percent]\n",
    "three_star_percent = [i/100 for i in three_star_percent]\n",
    "df1['Three_star'] = pd.Series(three_star_percent,index = df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "four_star_percent = list()\n",
    "for i in ratings_dicts:\n",
    "    four_star_percent.append(i.get('4'))\n",
    "four_star_percent = [int(re.sub(\"%\",\"\",i)) for i in four_star_percent]\n",
    "four_star_percent = [i/100 for i in four_star_percent]\n",
    "df1['Four_star'] = pd.Series(four_star_percent,index = df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "five_star_percent = list()\n",
    "for i in ratings_dicts:\n",
    "    five_star_percent.append(i.get('5'))\n",
    "five_star_percent = [int(re.sub(\"%\",\"\",i)) for i in five_star_percent]\n",
    "five_star_percent = [i/100 for i in five_star_percent]\n",
    "df1['Five_star'] = pd.Series(five_star_percent,index = df1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sales rank \n",
    "rank_list = df1.Rank.tolist()\n",
    "rank_list = [int(re.sub(\",\",\"\",i)) for i in rank_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4ef5723af0fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Rank'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# df1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df1['Rank'] = pd.Series(rank_list,index = df1.index)\n",
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sentiment Analysis following the class example\n",
    "p_url = 'http://ptrckprry.com/course/ssd/data/positive-words.txt'\n",
    "n_url = 'http://ptrckprry.com/course/ssd/data/negative-words.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "words = requests.get(p_url).content.decode('latin-1')\n",
    "# print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# codes from classnotes\n",
    "def get_words(url):\n",
    "    import requests\n",
    "    words = requests.get(url).content.decode('latin-1')\n",
    "\n",
    "    word_list = words.split('\\n')\n",
    "    index = 0\n",
    "    # Loop through the words/lines and remove what's not a word\n",
    "    while index < len(word_list):\n",
    "        word = word_list[index]\n",
    "        if ';' in word or not word:\n",
    "            word_list.pop(index)\n",
    "        else:\n",
    "            index += 1\n",
    "    return word_list\n",
    "\n",
    "# Get lists of positive and negative words\n",
    "positive_words = get_words(p_url)\n",
    "negative_words = get_words(n_url)\n",
    "\n",
    "\n",
    "def remove_punctuation(word):\n",
    "    if word and ((word[-1] >= 'a' and word[-1] <= 'z') or (word[-1] >= 'A' and word[-1] <= 'Z')):\n",
    "        return word\n",
    "    elif word:\n",
    "        return word[:-1]\n",
    "    else:\n",
    "        return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put all the reviews into bags of words to analyze positive/negative ratio\n",
    "reviews_grand_list = df1.Reviews.tolist()\n",
    "# reviews_grand_list\n",
    "reviews_bag_of_words = list()\n",
    "for i in reviews_grand_list:\n",
    "    bag_of_words = list()\n",
    "    for j in i.keys():\n",
    "        bag_of_words.append(i.get(j))\n",
    "    reviews_bag_of_words.append(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# total reviews of all the books\n",
    "total_reviews_bag = list()\n",
    "for i in range(len(reviews_bag_of_words)):\n",
    "    single_reviews_bag = list()\n",
    "    for j in range(len(reviews_bag_of_words[i])):\n",
    "        words_list = re.sub(\"[^\\w]\", \" \",  reviews_bag_of_words[i][j]).split()\n",
    "        single_reviews_bag.append(words_list)\n",
    "    single_reviews_bag = [x for y in single_reviews_bag for x in y]\n",
    "    total_reviews_bag.append(single_reviews_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['Reviews_bag'] = pd.Series(total_reviews_bag,index = df1.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
